{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![viz](https://static.vecteezy.com/system/resources/previews/000/184/369/original/flat-data-visualization-vector.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# y = intercept + slope(s) * Variable(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "main_performance = 1 + 2.1 * Coding_Exercise + 0 * Zodiac_Sign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is Regularization? Is a way of introducing penalties to (linear) models that are too simple or too complex while adjusting the coefficients to make them generalize better to new data. Another way to think about regularization is as penalties applied to regressions whose coefficients have become too large, and thus, sensitive to all kinds of inputs. These penalties, most notably L1 and L2, minimize the size of the coefficients and/or remove them completely. Here are two of the most important regularization methods.\n",
    "\n",
    "1. Ridge - Also called L2 penalty, is a regularization method (and an extension of linear regression) that forces the model parameters to stay as small as possible but without reaching zero. The parameter we optimize is called lambda ($\\lambda$) and it is usually initialized with the value 1.\n",
    "2. Least Absolute Shrinkage and Selection Operator (LASSO) - Lasso is another type of linear regression model where the coefficients of the variables that don't contribute much to a model, and whose coefficients are too large, will be effectively reduced to zero and removed/ignored by the model. The parameter we optimize is called lambda ($\\lambda$) and it is usually initialized with the value 1. In Python's scikit-learn package the parameter we optimise for is called `alpha`.\n",
    "\n",
    "\n",
    "Some Important Terms:\n",
    "- Overfitting: happens when your model fits the data too well or, more specifically, when it memorizes the training data and thus, fails to generalize well to new data. Another term used to refer to overfitting is high-variance. This is also a symptom of having too complex a model, e.g. a model with too many variables and not that many observations.\n",
    "- Underfitting: happens when your model is too simple and fails to capture the relationship between the target variable and the features.\n",
    "- bias-variance trade-off: having a good balance between the two above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # data manipulation and analysis package\n",
    "import numpy as np # numerical computing package\n",
    "import matplotlib.pyplot as plt # data visualisation package\n",
    "pd.options.display.max_columns = None # global setting for our session that allows us to see all the columns\n",
    "\n",
    "# machine learning functions we will need\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Hyp_attrition_bigdata.csv')\n",
    "df.head() # show the first 5 rows, add a number to the parentheses to see more rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the shape of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now select the columns that we will use for the models and take the id and target variables out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vars = df.drop(['new_id', 'quitnow'], axis='columns').columns\n",
    "print(train_vars.shape)\n",
    "print(train_vars[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now split our dataset into a training and a testing set. The training set will help us build and fine-tune the algorithm while the testing set will help us evaluate how the model performs with unseen data. We will use sklearn's `train_test_split` function and select and add 4 parameters to it\n",
    "- `array1` - our predictors or independent variables whose sample we want to split. This will return 2 datasets\n",
    "- `array2` - our target or dependent variables whose sample we want to split. This will return 2 arrays\n",
    "- `train_size` - the size of the training dataset. A number between 0 and 1 will split any datasets and/or arrays by that percentage. An integer will add that amount of rows to the training dataset\n",
    "- `random_state` - a seed to make sure our results are reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, df['quitnow'], train_size=102, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate one of the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train[train_vars].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling without scaling. This means that we will be evaluating the model with the data as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso() # first we instantiate (i.e. create and initialize) a variable with our model\n",
    "lasso.fit(X_train[train_vars], y_train) # we then fit the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set score: {:.2f}\".format(lasso.score(X_train[train_vars], y_train))) # let's now evaluate the R2 of our model with training data only\n",
    "print(\"Test set score: {:.2f}\".format(lasso.score(X_test[train_vars], y_test))) # let's now evaluate the R2 of our model with testing data only\n",
    "print(\"Number of features used: {}\".format(np.sum(lasso.coef_ != 0))) # let's sum up the columns whose coefficients are now 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try a different model with a smaller penalty and run more iterations of the regression. We will the following parameters\n",
    "- `alpha=` lambda is the main parameter of a lasso regression, and thus, what helps us penalize the coefficients\n",
    "- `random_state=` a seed for reproducibility purposes\n",
    "- `max_iter=` the amount of times the model will run in search of convergeance, i.e. the best fit for the line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_2 = Lasso(alpha=0.1, random_state=7, max_iter=10000) # first we instantiate (i.e. create and initialize) a variable with our model\n",
    "lasso_2.fit(X_train[train_vars], y_train) # we then fit the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set score: {:.2f}\".format(lasso_2.score(X_train[train_vars], y_train))) # let's now evaluate the R2 of our model with training data only\n",
    "print(\"Test set score: {:.2f}\".format(lasso_2.score(X_test[train_vars], y_test))) # let's now evaluate the R2 of our model with testing data only\n",
    "print(\"Number of features used: {}\".format(np.sum(lasso_2.coef_ != 0))) # let's sum up the columns whose coefficients are now 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_3 = Lasso(alpha=0.01, random_state=7, max_iter=1000000).fit(X_train[train_vars], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set score: {:.2f}\".format(lasso_3.score(X_train[train_vars], y_train))) # let's now evaluate the R2 of our model with training data only\n",
    "print(\"Test set score: {:.2f}\".format(lasso_3.score(X_test[train_vars], y_test))) # let's now evaluate the R2 of our model with testing data only\n",
    "print(\"Number of features used: {}\".format(np.sum(lasso_3.coef_ != 0))) # let's sum up the columns whose coefficients are now 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's scale our models and see what happens. Scaling means squizing the values of our variables between pre-specified values such a 0 and 1, the mean and a standard deviation, etc. In this case, we only want to use our training dataset for scaling and never our testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() # instantiate the scaler\n",
    "scaler.fit(X_train[train_vars]) # fit the trainin data only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.transform(X_train[train_vars]) # look at the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create two new training and testing datasets to continue the modeling stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = pd.concat([X_train[['new_id', 'quitnow']].reset_index(drop=True), # take the first two columns out\n",
    "                            pd.DataFrame(scaler.transform(X_train[train_vars]), columns=train_vars)], # scale the rest of the variables and create a dataframe\n",
    "                            axis=1) # do it all by the columns and not the rows\n",
    "\n",
    "X_test_scaled = pd.concat([X_test[['new_id', 'quitnow']].reset_index(drop=True), # take the first two columns out\n",
    "                           pd.DataFrame(scaler.transform(X_test[train_vars]), columns=train_vars)], # scale the rest of the variables and create a dataframe\n",
    "                           axis=1) # do it all by the columns and not the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.head() # look at the scaled variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the modeling from above but with the new scaled datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_4 = Lasso(random_state=7).fit(X_train_scaled[train_vars], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set score: {:.2f}\".format(lasso_4.score(X_train_scaled[train_vars], y_train))) # let's now evaluate the R2 of our model with the scaled training data only\n",
    "print(\"Test set score: {:.2f}\".format(lasso_4.score(X_test_scaled[train_vars], y_test))) # let's now evaluate the R2 of our model with the scaled testing data only\n",
    "print(\"Number of features used: {}\".format(np.sum(lasso_4.coef_ != 0))) # let's sum up the columns whose coefficients are now 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_5 = Lasso(alpha=0.1, random_state=7, max_iter=100000).fit(X_train_scaled[train_vars], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set score: {:.2f}\".format(lasso_5.score(X_train_scaled[train_vars], y_train))) # let's now evaluate the R2 of our model with the scaled training data only\n",
    "print(\"Test set score: {:.2f}\".format(lasso_5.score(X_test_scaled[train_vars], y_test))) # let's now evaluate the R2 of our model with the scaled testing data only\n",
    "print(\"Number of features used: {}\".format(np.sum(lasso_5.coef_ != 0))) # let's sum up the columns whose coefficients are now 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_6 = Lasso(alpha=0.01, random_state=7, max_iter=100000).fit(X_train_scaled[train_vars], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set score: {:.2f}\".format(lasso_6.score(X_train_scaled[train_vars], y_train))) # let's now evaluate the R2 of our model with the scaled training data only\n",
    "print(\"Test set score: {:.2f}\".format(lasso_6.score(X_test_scaled[train_vars], y_test))) # let's now evaluate the R2 of our model with the scaled testing data only\n",
    "print(\"Number of features used: {}\".format(np.sum(lasso_6.coef_ != 0))) # let's sum up the columns whose coefficients are now 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation allows us to test small combinations of the independent variables and the dependent variable in any dataset. Let's check it out with the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(Lasso(alpha=0.1), X_train_scaled[train_vars], y_train, cv=10, n_jobs=-1)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Absolute Best Scores %.3f and Standard Deviation (%.3f)' % (np.mean(np.abs(scores)), np.std(np.abs(scores))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a dictionary to search for the best parameter lambda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = dict()\n",
    "grid['alpha'] = np.arange(0, 1, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(Lasso(max_iter=100000), grid, cv=10, n_jobs=-1) # we will shuffle the data 10 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = search.fit(X_train_scaled[train_vars], y_train) # fit the train datasets\n",
    "print('Score: %.3f' % results.best_score_) # evaluate best score\n",
    "print('Config: %s' % results.best_params_) # evaluate best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now select the best features/columns/variables with our new lambda and then create one last model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = SelectFromModel(Lasso(alpha=0.03, max_iter=100000, random_state=7))\n",
    "selection.fit(X_train_scaled[train_vars], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection.get_support() # shows the variables we need as Trues and Falses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = X_train_scaled[train_vars].columns[selection.get_support()] # select only the variables we need\n",
    "selected_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the variables we choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Variables: {}\".format(X_train_scaled.shape[1]))\n",
    "print(\"Variables Selected: {}\".format(len(selected_cols)))\n",
    "print(\"Variables whose coefficient got shrank to zero: {}\".format(np.sum(selection.estimator_.coef_ == 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat modeling exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_7 = Lasso(alpha=0.03, max_iter=100000, random_state=7).fit(X_train_scaled[selected_cols], y_train)\n",
    "\n",
    "print(\"Training Set Score: {}\".format(lasso_7.score(X_train_scaled[selected_cols], y_train)))\n",
    "print(\"Test Set Score: {}\".format(lasso_7.score(X_test_scaled[selected_cols], y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = y_test - lasso_7.predict(X_test_scaled[selected_cols])\n",
    "errors.hist(bins=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Important Variables\n",
    "\n",
    "Let's now visually inspect the most important variables of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = pd.Series(np.abs(lasso_7.coef_.ravel()))\n",
    "importance.index = selected_cols\n",
    "importance.sort_values(inplace=True, ascending=False)\n",
    "importance.plot.bar(figsize=(18, 6))\n",
    "plt.ylabel(\"Lasso Coefficients\")\n",
    "plt.title(\"Feature Importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally - All of the Above in One Go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, df['quitnow'], train_size=102, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train[train_vars])\n",
    "X_train_scaled = pd.concat([X_train[['new_id', 'quitnow']].reset_index(drop=True),\n",
    "                            pd.DataFrame(scaler.transform(X_train[train_vars]), columns=train_vars)], axis=1)\n",
    "\n",
    "X_test_scaled = pd.concat([X_test[['new_id', 'quitnow']].reset_index(drop=True),\n",
    "                           pd.DataFrame(scaler.transform(X_test[train_vars]), columns=train_vars)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LassoCV(cv=10, max_iter=100000, random_state=7, n_jobs=-1).fit(X_train_scaled[train_vars], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Set Score: {}\".format(reg.score(X_train_scaled[train_vars], y_train)))\n",
    "print(\"Test Set Score: {}\".format(reg.score(X_test_scaled[train_vars], y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "people",
   "language": "python",
   "name": "people"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
